{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gdYC-cpz7eP",
        "outputId": "8c989331-5247-4fb5-9444-5c4b0faf7757"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of train_images: (1886, 128, 128, 3)\n",
            "Data type of train_images: float64\n",
            "Shape of train_labels: (1886,)\n",
            "Data type of train_labels: int64\n",
            "Unique labels in train_labels: [0 1 2 3]\n",
            "Shape of train_images_seg: (1775, 128, 128, 3)\n",
            "Data type of train_images_seg: float64\n",
            "Shape of train_masks: (1834, 128, 128, 1)\n",
            "Data type of train_masks: float64\n"
          ]
        }
      ],
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "IMG_WIDTH = 128\n",
        "IMG_HEIGHT = 128\n",
        "\n",
        "def load_classification_data(directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "    class_names = sorted([d for d in os.listdir(directory) if os.path.isdir(os.path.join(directory, d)) and d != 'annotations'])\n",
        "    for class_index, class_name in enumerate(class_names):\n",
        "        class_dir = os.path.join(directory, class_name)\n",
        "        for filename in os.listdir(class_dir):\n",
        "            if filename.endswith('.jpg') or filename.endswith('.png'):\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                img = Image.open(img_path).resize((IMG_WIDTH, IMG_HEIGHT))\n",
        "                img_array = np.array(img)\n",
        "                if img_array.shape == (IMG_WIDTH, IMG_HEIGHT, 3):\n",
        "                    images.append(img_array / 255.0)\n",
        "                    labels.append(class_index)\n",
        "    images = np.array(images)\n",
        "    labels = np.array(labels)\n",
        "    return images, labels, class_names\n",
        "\n",
        "train_images, train_labels, class_names = load_classification_data('/content/drive/MyDrive/DIP Data Upload/train')\n",
        "\n",
        "# Verify shapes and data types of train_images and train_labels\n",
        "print(f\"Shape of train_images: {train_images.shape}\")\n",
        "print(f\"Data type of train_images: {train_images.dtype}\")\n",
        "print(f\"Shape of train_labels: {train_labels.shape}\")\n",
        "print(f\"Data type of train_labels: {train_labels.dtype}\")\n",
        "print(f\"Unique labels in train_labels: {np.unique(train_labels)}\")\n",
        "\n",
        "def load_segmentation_data(directory):\n",
        "    images = []\n",
        "    masks = []\n",
        "    for class_name in ['gun', 'knife', 'shuriken']:\n",
        "        class_dir = os.path.join(directory, class_name)\n",
        "        for filename in os.listdir(class_dir):\n",
        "            if filename.endswith('.jpg') or filename.endswith('.png'):\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                img = Image.open(img_path).resize((IMG_WIDTH, IMG_HEIGHT))\n",
        "                img_array = np.array(img)\n",
        "                if img_array.shape == (IMG_WIDTH, IMG_HEIGHT, 3):\n",
        "                    images.append(img_array / 255.0)\n",
        "\n",
        "        mask_class_dir = os.path.join(directory, 'annotations', class_name)\n",
        "        for filename in os.listdir(mask_class_dir):\n",
        "            if filename.endswith('.png'):\n",
        "                mask_path = os.path.join(mask_class_dir, filename)\n",
        "                mask = Image.open(mask_path).resize((IMG_WIDTH, IMG_HEIGHT)).convert('L')  # Convert to grayscale\n",
        "                mask_array = np.array(mask) / 255.0\n",
        "                if mask_array.shape == (IMG_WIDTH, IMG_HEIGHT):\n",
        "                    masks.append(mask_array)\n",
        "\n",
        "    # Ensure all masks have the same shape\n",
        "    mask_shapes = [mask.shape for mask in masks]\n",
        "    unique_shapes = set(mask_shapes)\n",
        "    if len(unique_shapes) > 1:\n",
        "        raise ValueError(\"Masks have inconsistent shapes.\")\n",
        "\n",
        "    return np.array(images), np.expand_dims(np.array(masks), axis=-1)  # Add channel dimension for masks\n",
        "\n",
        "train_images_seg, train_masks = load_segmentation_data('/content/drive/MyDrive/DIP Data Upload/train')\n",
        "\n",
        "print(f\"Shape of train_images_seg: {train_images_seg.shape}\")\n",
        "print(f\"Data type of train_images_seg: {train_images_seg.dtype}\")\n",
        "print(f\"Shape of train_masks: {train_masks.shape}\")\n",
        "print(f\"Data type of train_masks: {train_masks.dtype}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWiynS5Y0YGE",
        "outputId": "b9632268-d823-4465-b86b-449653bbe4b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "48/48 [==============================] - 44s 897ms/step - loss: 0.7951 - accuracy: 0.5643 - val_loss: 4.9121 - val_accuracy: 0.0582\n",
            "Epoch 2/10\n",
            "48/48 [==============================] - 40s 831ms/step - loss: 0.5965 - accuracy: 0.6393 - val_loss: 5.4450 - val_accuracy: 0.2698\n",
            "Epoch 3/10\n",
            "48/48 [==============================] - 48s 1s/step - loss: 0.5546 - accuracy: 0.6711 - val_loss: 6.2988 - val_accuracy: 0.2249\n",
            "Epoch 4/10\n",
            "48/48 [==============================] - 41s 848ms/step - loss: 0.5367 - accuracy: 0.6810 - val_loss: 6.1782 - val_accuracy: 0.1005\n",
            "Epoch 5/10\n",
            "48/48 [==============================] - 43s 886ms/step - loss: 0.5196 - accuracy: 0.7082 - val_loss: 8.0875 - val_accuracy: 0.1429\n",
            "Epoch 6/10\n",
            "48/48 [==============================] - 41s 862ms/step - loss: 0.4987 - accuracy: 0.7241 - val_loss: 7.3138 - val_accuracy: 0.1323\n",
            "Epoch 7/10\n",
            "48/48 [==============================] - 41s 851ms/step - loss: 0.4795 - accuracy: 0.7381 - val_loss: 8.7355 - val_accuracy: 0.2381\n",
            "Epoch 8/10\n",
            "48/48 [==============================] - 43s 910ms/step - loss: 0.4729 - accuracy: 0.7381 - val_loss: 8.9717 - val_accuracy: 0.1058\n",
            "Epoch 9/10\n",
            "48/48 [==============================] - 40s 831ms/step - loss: 0.4583 - accuracy: 0.7493 - val_loss: 8.6531 - val_accuracy: 0.1720\n",
            "Epoch 10/10\n",
            "48/48 [==============================] - 43s 897ms/step - loss: 0.4471 - accuracy: 0.7473 - val_loss: 10.3435 - val_accuracy: 0.1561\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7bcf4141cf40>"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "# Build the classification model\n",
        "classification_model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_WIDTH, IMG_HEIGHT, 3)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Flatten(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(4, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "classification_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "classification_model.fit(train_images, train_labels, epochs=10, batch_size=32, validation_split=0.2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3QRfRCuRGXP",
        "outputId": "807cb929-2486-4cb2-f06c-c944f9aebc89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 5s 319ms/step\n",
            "Accuracy: 0.4178498985801217\n",
            "Confusion Matrix:\n",
            "[[113 134   0   0]\n",
            " [ 74  93   0   0]\n",
            " [ 42  13   0   0]\n",
            " [ 22   2   0   0]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "def load_data(directory):\n",
        "    images = []\n",
        "    labels = []\n",
        "    class_names = sorted([d for d in os.listdir(directory) if os.path.isdir(os.path.join(directory, d)) and d != 'annotations'])\n",
        "    for class_index, class_name in enumerate(class_names):\n",
        "        class_dir = os.path.join(directory, class_name)\n",
        "        for filename in os.listdir(class_dir):\n",
        "            if filename.endswith('.jpg') or filename.endswith('.png'):\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                img = Image.open(img_path).resize((IMG_WIDTH, IMG_HEIGHT))\n",
        "                img_array = np.array(img)\n",
        "                if img_array.shape == (IMG_WIDTH, IMG_HEIGHT, 3):\n",
        "                    images.append(img_array / 255.0)\n",
        "                    labels.append(class_index)\n",
        "    images = np.array(images)\n",
        "    labels = np.array(labels)\n",
        "    return images, labels, class_names\n",
        "\n",
        "\n",
        "# Assuming val_images and val_labels are your validation data\n",
        "val_images, val_labels, classnames1 = load_data('/content/drive/MyDrive/DIP Data Upload/test')  # Adjust path as needed\n",
        "\n",
        "# Make predictions on the validation set\n",
        "val_predictions = classification_model.predict(val_images)\n",
        "val_pred_labels = np.argmax(val_predictions, axis=1)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(val_labels, val_pred_labels)\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "\n",
        "# Calculate confusion matrix\n",
        "conf_matrix = confusion_matrix(val_labels, val_pred_labels)\n",
        "print(f\"Confusion Matrix:\\n{conf_matrix}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4csyw7F9417k",
        "outputId": "a52b0209-98fe-4590-849c-16a32e4c9289"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)        [(None, 128, 128, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)           (None, 128, 128, 64)         1792      ['input_1[0][0]']             \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)           (None, 128, 128, 64)         36928     ['conv2d_2[0][0]']            \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPoolin  (None, 64, 64, 64)           0         ['conv2d_3[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)           (None, 64, 64, 128)          73856     ['max_pooling2d_2[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)           (None, 64, 64, 128)          147584    ['conv2d_4[0][0]']            \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPoolin  (None, 32, 32, 128)          0         ['conv2d_5[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)           (None, 32, 32, 256)          295168    ['max_pooling2d_3[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)           (None, 32, 32, 256)          590080    ['conv2d_6[0][0]']            \n",
            "                                                                                                  \n",
            " max_pooling2d_4 (MaxPoolin  (None, 16, 16, 256)          0         ['conv2d_7[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)           (None, 16, 16, 512)          1180160   ['max_pooling2d_4[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)           (None, 16, 16, 512)          2359808   ['conv2d_8[0][0]']            \n",
            "                                                                                                  \n",
            " max_pooling2d_5 (MaxPoolin  (None, 8, 8, 512)            0         ['conv2d_9[0][0]']            \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)          (None, 8, 8, 1024)           4719616   ['max_pooling2d_5[0][0]']     \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)          (None, 8, 8, 1024)           9438208   ['conv2d_10[0][0]']           \n",
            "                                                                                                  \n",
            " up_sampling2d (UpSampling2  (None, 16, 16, 1024)         0         ['conv2d_11[0][0]']           \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 16, 16, 1536)         0         ['up_sampling2d[0][0]',       \n",
            "                                                                     'conv2d_9[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)          (None, 16, 16, 512)          7078400   ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)          (None, 16, 16, 512)          2359808   ['conv2d_12[0][0]']           \n",
            "                                                                                                  \n",
            " up_sampling2d_1 (UpSamplin  (None, 32, 32, 512)          0         ['conv2d_13[0][0]']           \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate  (None, 32, 32, 768)          0         ['up_sampling2d_1[0][0]',     \n",
            " )                                                                   'conv2d_7[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)          (None, 32, 32, 256)          1769728   ['concatenate_1[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)          (None, 32, 32, 256)          590080    ['conv2d_14[0][0]']           \n",
            "                                                                                                  \n",
            " up_sampling2d_2 (UpSamplin  (None, 64, 64, 256)          0         ['conv2d_15[0][0]']           \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate  (None, 64, 64, 384)          0         ['up_sampling2d_2[0][0]',     \n",
            " )                                                                   'conv2d_5[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)          (None, 64, 64, 128)          442496    ['concatenate_2[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)          (None, 64, 64, 128)          147584    ['conv2d_16[0][0]']           \n",
            "                                                                                                  \n",
            " up_sampling2d_3 (UpSamplin  (None, 128, 128, 128)        0         ['conv2d_17[0][0]']           \n",
            " g2D)                                                                                             \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate  (None, 128, 128, 192)        0         ['up_sampling2d_3[0][0]',     \n",
            " )                                                                   'conv2d_3[0][0]']            \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)          (None, 128, 128, 64)         110656    ['concatenate_3[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_19 (Conv2D)          (None, 128, 128, 64)         36928     ['conv2d_18[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_20 (Conv2D)          (None, 128, 128, 1)          65        ['conv2d_19[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 31378945 (119.70 MB)\n",
            "Trainable params: 31378945 (119.70 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, concatenate\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "def dice_coefficient(y_true, y_pred):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + 1) / (K.sum(y_true_f) + K.sum(y_pred_f) + 1)\n",
        "\n",
        "def unet_model(input_size=(128, 128, 3)):\n",
        "    inputs = Input(input_size)\n",
        "\n",
        "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    c1 = Conv2D(64, (3, 3), activation='relu', padding='same')(c1)\n",
        "    p1 = MaxPooling2D((2, 2))(c1)\n",
        "\n",
        "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(p1)\n",
        "    c2 = Conv2D(128, (3, 3), activation='relu', padding='same')(c2)\n",
        "    p2 = MaxPooling2D((2, 2))(c2)\n",
        "\n",
        "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(p2)\n",
        "    c3 = Conv2D(256, (3, 3), activation='relu', padding='same')(c3)\n",
        "    p3 = MaxPooling2D((2, 2))(c3)\n",
        "\n",
        "    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(p3)\n",
        "    c4 = Conv2D(512, (3, 3), activation='relu', padding='same')(c4)\n",
        "    p4 = MaxPooling2D((2, 2))(c4)\n",
        "\n",
        "    c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(p4)\n",
        "    c5 = Conv2D(1024, (3, 3), activation='relu', padding='same')(c5)\n",
        "\n",
        "    u6 = UpSampling2D((2, 2))(c5)\n",
        "    u6 = concatenate([u6, c4])\n",
        "    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(u6)\n",
        "    c6 = Conv2D(512, (3, 3), activation='relu', padding='same')(c6)\n",
        "\n",
        "    u7 = UpSampling2D((2, 2))(c6)\n",
        "    u7 = concatenate([u7, c3])\n",
        "    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(u7)\n",
        "    c7 = Conv2D(256, (3, 3), activation='relu', padding='same')(c7)\n",
        "\n",
        "    u8 = UpSampling2D((2, 2))(c7)\n",
        "    u8 = concatenate([u8, c2])\n",
        "    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(u8)\n",
        "    c8 = Conv2D(128, (3, 3), activation='relu', padding='same')(c8)\n",
        "\n",
        "    u9 = UpSampling2D((2, 2))(c8)\n",
        "    u9 = concatenate([u9, c1])\n",
        "    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(u9)\n",
        "    c9 = Conv2D(64, (3, 3), activation='relu', padding='same')(c9)\n",
        "\n",
        "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(c9)\n",
        "\n",
        "    model = Model(inputs=[inputs], outputs=[outputs])\n",
        "    model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy', dice_coefficient])\n",
        "\n",
        "    return model\n",
        "\n",
        "segmentation_model = unet_model()\n",
        "segmentation_model.summary()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "We-B2uHZ7da6",
        "outputId": "4e5ca133-9275-4445-ccf0-ec5b1b67e45b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "178/178 [==============================] - 3325s 19s/step - loss: 0.0028 - accuracy: 0.9423 - dice_coefficient: 0.0132 - val_loss: 0.0062 - val_accuracy: 0.9039 - val_dice_coefficient: 0.0077\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7bcf4141ca30>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "segmentation_model.fit(train_images_seg, train_masks, epochs=1, batch_size=8, validation_split=0.2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ajL10rhA_aD"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "def calculate_dice_coefficient(y_true, y_pred):\n",
        "    y_true_f = y_true.flatten()\n",
        "    y_pred_f = y_pred.flatten()\n",
        "    intersection = np.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + 1) / (np.sum(y_true_f) + np.sum(y_pred_f) + 1)\n",
        "\n",
        "def inference_on_test_data(test_directory, classification_model, segmentation_model):\n",
        "    class_names = ['gun', 'knife', 'shuriken', 'safe']\n",
        "    output_directory = '/content/drive/MyDrive/DIP Data Upload/output'\n",
        "    os.makedirs(output_directory, exist_ok=True)\n",
        "\n",
        "    for class_name in class_names:\n",
        "        class_dir = os.path.join(test_directory, class_name)\n",
        "        output_class_dir = os.path.join(output_directory, class_name)\n",
        "        os.makedirs(output_class_dir, exist_ok=True)\n",
        "\n",
        "        for filename in os.listdir(class_dir):\n",
        "            if filename.endswith('.jpg') or filename.endswith('.png'):\n",
        "                img_path = os.path.join(class_dir, filename)\n",
        "                img = Image.open(img_path).resize((IMG_WIDTH, IMG_HEIGHT))\n",
        "                img_array = np.array(img) / 255.0\n",
        "\n",
        "                # Classification\n",
        "                pred_class = np.argmax(classification_model.predict(np.expand_dims(img_array, axis=0)), axis=1)[0]\n",
        "                pred_class_name = class_names[pred_class]\n",
        "\n",
        "                # Segmentation\n",
        "                if pred_class_name in ['gun', 'knife', 'shuriken']:\n",
        "                    mask_pred = segmentation_model.predict(np.expand_dims(img_array, axis=0))[0]\n",
        "                    mask_pred = (mask_pred > 0.5).astype(np.uint8)  # Threshold the prediction\n",
        "                    mask_pred_resized = cv2.resize(mask_pred, (img.width, img.height), interpolation=cv2.INTER_NEAREST)\n",
        "                    segmented_image = cv2.bitwise_and(np.array(img), np.array(img), mask=mask_pred_resized.squeeze())\n",
        "\n",
        "                    # Calculate and print Dice coefficient\n",
        "                    mask_true_path = os.path.join(test_directory, 'annotations', pred_class_name, filename)\n",
        "                    if os.path.exists(mask_true_path):\n",
        "                        mask_true = Image.open(mask_true_path).resize((img.width, img.height)).convert('L')\n",
        "                        mask_true_array = np.array(mask_true) / 255.0\n",
        "                        dice_coeff = calculate_dice_coefficient(mask_true_array, mask_pred_resized.squeeze())\n",
        "                        print(f\"Dice coefficient for {filename} ({pred_class_name}): {dice_coeff:.4f}\")\n",
        "\n",
        "                    segmented_image_path = os.path.join(output_class_dir, filename)\n",
        "                    cv2.imwrite(segmented_image_path, segmented_image)\n",
        "                else:\n",
        "                    img.save(os.path.join(output_class_dir, filename))\n",
        "\n",
        "# Run inference on the test data\n",
        "test_directory = '/content/drive/MyDrive/DIP Data Upload/test'\n",
        "inference_on_test_data(test_directory, classification_model, segmentation_model)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}